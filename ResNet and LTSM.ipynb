{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c908d8-3e98-4171-9161-5cabc56bacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "\n",
    "import torchaudio\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944756c4-108c-40cc-bdc0-229ea8ee06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个自定义数据集类\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_list, label_list):\n",
    "        self.file_list = file_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        # 使用 Librosa 加载音频文件，并将其转换为梅尔频谱图\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=512, n_mels=80)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_spec_db = np.expand_dims(mel_spec_db, axis=0)\n",
    "\n",
    "        # 返回梅尔频谱图和标签\n",
    "        return mel_spec_db, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c183fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#残差模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "#定义残差块ResBlock\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        #残差块内连续的2个卷积层\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            #shortcut，这里为了跟2个卷积层的结果结构一致，要做处理\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        #将2个卷积层的输出跟处理过的x相加，实现ResNet的基本结构\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    " \n",
    "#实现ResNet-18模型\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, num_classes=20):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResBlock, 256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(ResBlock, 512, 2, stride=2)        \n",
    "        self.fc = nn.Linear(5120, num_classes)\n",
    "    #这个函数主要是用来，重复同一个残差块    \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #在这里，整个ResNet18的结构就很清晰了\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a81b150-96c8-4ee5-8c6c-31016363a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = \"Red-billed Starling,Intermediate Egret,Blue-and-white Flycatcher,Pin-tailed Snipe,Eastern Marsh-Harrier,Manchurian Reed Warbler,Chinese Pond-Heron,Rock Bunting,Isabelline Shrike,Japanese Scops-Owl,Red-backed Shrike,Bronzed Drongo,Claudia's Leaf Warbler,Common Myna,Koklass Pheasant,Barred Warbler,Besra,Pallid Harrier,Tickell's Leaf Warbler,Gray-cheeked Warbler\".split(',')\n",
    "\n",
    "NUM_CLASSES = len(idx_to_label)\n",
    "\n",
    "label_to_idx = {idx_to_label[i]: i for i in range(NUM_CLASSES)}\n",
    "\n",
    "train_data_path = 'data/train'\n",
    "test_data_path = 'data/test'\n",
    "\n",
    "label_to_idx = {value: key for key, value in label_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57f08b6-e61f-4e52-8ee9-98ccc1cc52dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 100007.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<00:00, 99030.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 100222.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 99/99 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "train_files=[]\n",
    "train_labels =[]\n",
    "for label in label_to_idx:\n",
    "        label_dir = f'{train_data_path}/{label}'\n",
    "        for wav_file in tqdm(os.listdir(label_dir)):\n",
    "            train_files.append(label_dir + f'/{wav_file}')\n",
    "            train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd2ec63-9b44-485d-8e36-616825b29fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e3fe82-5964-4bf6-87f9-c0f044db5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb27edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''\n",
    "(1)random_state不填或者为0时，每次都不同；其余值表示不同随机数\n",
    "(2)shuffle表示是否在分割之前对数据进行洗牌（默认True）\n",
    "'''\n",
    "train_f, test_f, train_l, test_l = train_test_split(train_files, train_labels, test_size=0.20,random_state=42,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d67276a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1484caec-9084-46ad-b606-a68e65cc8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train_f, train_l)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = AudioDataset(test_f, test_l)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20523ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResNet()\n",
    "model = ResNet(ResBlock)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda84864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (left): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=5120, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d5b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for i in range(epoch):\n",
    "        for idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print('epoch: {}, loss: {}'.format(i+1, loss.item()))\n",
    "                #torch.save(model.state_dict(), './model/yesno_net.pkl')\n",
    "                #torch.save(optimizer.state_dict(), './model/yesno_optimizer.pkl')\n",
    "            idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63908b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test(model):\n",
    "    loss_list = []\n",
    "    #sample_num = 0\n",
    "    acc_num = 0\n",
    "    f1 = 0\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #cur_loss = criterion(outputs, labels).cpu()\n",
    "            # outputs中的每一项均为包含两个位于0和1之间的浮点数的数组，较大浮点数所在位置即为预测值\n",
    "            pred = outputs.argmax(dim=1, keepdim=True).cpu()  # 将pred转移到CPU上\n",
    "            labels = labels.cpu()  # 将labels转移到CPU上\n",
    "\n",
    "            # 统计预测正确的个数\n",
    "            acc_num += pred.eq(labels.view_as(pred)).sum()\n",
    "            # 记录预测的样本数\n",
    "            #sample_num = sample_num + labels.size()[0]\n",
    "\n",
    "            # 计算F1分数，注意我们需要将预测和标签转换为NumPy数组\n",
    "            f1 += f1_score(labels.numpy(), pred.numpy(), average='micro')\n",
    "\n",
    "            #loss_list.append(cur_loss)\n",
    "\n",
    "    # 计算平均F1分数\n",
    "    f1 = f1 / len(test_loader)\n",
    "\n",
    "    print('平均准确率:{}'.format(acc_num / len(test_loader)))\n",
    "    print('F1 micro 分数为：',f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3352fc4-4d7d-4830-b684-2c656c656693",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'ResNet.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44bd4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均准确率:0.7777777910232544\n",
      "F1 micro 分数为： 0.024305555555555556\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "462c94aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14],\n",
      "        [ 4],\n",
      "        [16],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [13],\n",
      "        [ 9],\n",
      "        [14],\n",
      "        [ 9],\n",
      "        [ 9],\n",
      "        [16],\n",
      "        [14],\n",
      "        [ 9],\n",
      "        [16],\n",
      "        [16],\n",
      "        [ 9],\n",
      "        [16],\n",
      "        [11],\n",
      "        [16],\n",
      "        [ 4],\n",
      "        [16],\n",
      "        [ 8],\n",
      "        [16],\n",
      "        [ 4],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [ 8],\n",
      "        [14],\n",
      "        [ 1]])\n",
      "7\n",
      "tensor([[13],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [13],\n",
      "        [13],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [13],\n",
      "        [14],\n",
      "        [ 6],\n",
      "        [16],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [ 6],\n",
      "        [16],\n",
      "        [ 4],\n",
      "        [16],\n",
      "        [16],\n",
      "        [16],\n",
      "        [ 4],\n",
      "        [14],\n",
      "        [14],\n",
      "        [14],\n",
      "        [11],\n",
      "        [16],\n",
      "        [16],\n",
      "        [ 9],\n",
      "        [ 9],\n",
      "        [ 4],\n",
      "        [ 9]])\n",
      "7\n",
      "tensor([[ 4],\n",
      "        [ 9],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [11],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 3],\n",
      "        [16],\n",
      "        [ 3],\n",
      "        [11],\n",
      "        [11],\n",
      "        [ 9],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [13],\n",
      "        [ 9],\n",
      "        [16],\n",
      "        [16],\n",
      "        [16],\n",
      "        [ 9],\n",
      "        [14],\n",
      "        [ 4]])\n",
      "7\n",
      "tensor([[ 1],\n",
      "        [14],\n",
      "        [16],\n",
      "        [ 9],\n",
      "        [14],\n",
      "        [11],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 3],\n",
      "        [15],\n",
      "        [ 3],\n",
      "        [11],\n",
      "        [11],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [11],\n",
      "        [ 4],\n",
      "        [ 3],\n",
      "        [ 6],\n",
      "        [ 3],\n",
      "        [ 6],\n",
      "        [13],\n",
      "        [13],\n",
      "        [13],\n",
      "        [13],\n",
      "        [ 9],\n",
      "        [ 8],\n",
      "        [14],\n",
      "        [11],\n",
      "        [14],\n",
      "        [11]])\n",
      "7\n",
      "tensor([[13],\n",
      "        [13],\n",
      "        [11],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 8],\n",
      "        [11],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 3],\n",
      "        [11],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [ 3],\n",
      "        [13],\n",
      "        [ 9],\n",
      "        [13],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 6]])\n",
      "7\n",
      "tensor([[ 7],\n",
      "        [11],\n",
      "        [ 8],\n",
      "        [ 6],\n",
      "        [ 3],\n",
      "        [11],\n",
      "        [ 8],\n",
      "        [14],\n",
      "        [14],\n",
      "        [11],\n",
      "        [ 6],\n",
      "        [ 8],\n",
      "        [ 3],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [15],\n",
      "        [15],\n",
      "        [16],\n",
      "        [12],\n",
      "        [15],\n",
      "        [13],\n",
      "        [13],\n",
      "        [13],\n",
      "        [ 3],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [14],\n",
      "        [ 4],\n",
      "        [14],\n",
      "        [ 4]])\n",
      "7\n",
      "tensor([[13],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 4],\n",
      "        [11],\n",
      "        [13],\n",
      "        [ 4],\n",
      "        [ 3],\n",
      "        [ 1],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [13],\n",
      "        [13],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [14]])\n",
      "7\n",
      "tensor([[14],\n",
      "        [ 4],\n",
      "        [ 8],\n",
      "        [ 3],\n",
      "        [11],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 4],\n",
      "        [ 9],\n",
      "        [ 8],\n",
      "        [ 8],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 6],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [13],\n",
      "        [ 8],\n",
      "        [11],\n",
      "        [13],\n",
      "        [ 6],\n",
      "        [16],\n",
      "        [ 1],\n",
      "        [ 3],\n",
      "        [ 8]])\n",
      "7\n",
      "tensor([[ 4],\n",
      "        [ 4],\n",
      "        [11]])\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "acc_num = 0\n",
    "for idx, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        pred = outputs.argmax(dim=1, keepdim=True).cpu() \n",
    "        print(pred)\n",
    "        labels = labels.cpu()  \n",
    "        #print(labels,pred)\n",
    "        acc_num = acc_num + pred.eq(labels.view_as(pred)).sum().item()\n",
    "    print(acc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54cc563-28bf-4e16-bff1-4f37cbc2d15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
